\chapter{Fazit}
Im letzten Kapitel dieser Arbeit wird anhand der Ergebnisse bezug zur Lösung der Problemstellung genommen. Ebenso wird die in Kapitel \ref{sec:goal} aufgestellte Zielstellung überprüft, so dass anhand dieser der Erfolg der Arbeit gemessen werden kann. Ein kurzer Ausblick zeigt die Möglichkeiten sowie das Potenzial der angewandten Technologie und der gewonnenen Erkenntnisse.

\section{Schlussfolgerung}
Im Rahmen dieser Arbeit wurden dem Leser in Kapitel \ref{chap:basics} relevante technische Grundlagen vermittelt, um den Kontext, die Herangehensweise sowie angewandte Technologien besser zu verstehen.\\ Um den Kernpunkt des Themas bearbeiten zu können, war eine Konzeption sowie Implementaion eines automatisierten Testerstellungssystems notwendig. Diese wurde detailreich und nachvollziehbar in den Kapiteln \ref{chapter:concept} und \ref{chapter:impl} durchgeführt und ermöglichte die Grundlage einer anschließenden Analyse.\\ Die Durchführung erfolgte anhand verschiedener Projekte mit unterschiedlichen Komplexitätsgraden, durch welche eine aussagekräftige Anzahl an Tests generiert werden konnte. Zur Evaluierung der Ergebnisse wurde ein fest definiertes Bewertungsverfahren mit klar gesetzten Metriken genutzt sowie im Anschluss daran der Vergleich zur reellen Arbeitswelt gezogen.\\ Betrachtet man die am Anfang der Arbeit beschriebenen Ziele mit den eben genannten Umsetzungen kann schlussfolgernd gesagt werden, dass sowohl die Grundlage einer aussagekräftigen Analyse als auch die Analyse selbst erfolgreich umgesetzt wurde.\\\\
Die im Kapitel \ref{sec:prob} beschriebene Problemstellung eröffnete die Frage inwiefern Sprachmodelle die Arbeit von Testern, im Kontext der Generierung von \textit{JUnit Tests} ersetzen können und in welcher Qualität sie deren Arbeit übernehmen. \\Anhand der Analyse wurde deutlich, dass das Sprachmodell \textit{GPT-4o} in allen verwendeten Projekten, gute bis sehr gute Ergebnisse erzielte. Auch bei steigendem Komplexitätsgrad des Projektes erreichte \textit{Unitcraft} ein akzeptables und konsequentes Ergebnis. Zieht man den direkten Vergleich mit manuellen Testergebnissen, wurde auch dort deutlich, dass \textit{GPT-4o} in den meisten Fällen die bessere \textit{Coverage} erzielte. Dabei gilt zu berücksichtigen, dass dies abhängig von den Ergebnissen der SENEC GmbH ist und dementsprechend nicht für die Allgemeinheit aller Tester gilt. Da die gewählten Projekte und manuellen Testergebnisse der reellen Arbeitswelt entstammen, ist dieser Vergleich trotz alledem von Bedeutung. Somit kann man schlussfolgern, dass der Aspekt der \textit{Unit Test}-Erstellung zum Erreichen einer zufriedenstellenden \textit{Coverage} ersetzbar ist.\\ Nach Betrachtung der Erfolgsquote wurde jedoch deutlich, dass die Qualität der einzelnen Tests im Vergleich zu den manuellen Tests nicht zufriedenstellend ist. Es entsteht ein hoher Anteil an nicht verwendbarem Code aufgrund von \textit{Errors}, die während der Testdurchführung auftreten. Auf Grundlage dieser Erkenntnisse wird klar, dass ein Sprachmodell die Arbeit eines Testers nur teilweise und nicht vollständig übernehmen kann, da zur Erhaltung der Qualität im Projekt ein manuelles Analysieren des generierten Testcodes erforderlich ist. \\Da es sich hierbei um eine Analyse der rohen Ergebnisse eines Sprachmodells handelt, bietet diese Schlussfolgerung eine gute Basis, um mit speziellen Funktionalitäten innerhalb eines automatisierten Testerstellungssystems die eben genannten Qualitätsprobleme sowie in Kapitel \ref{sec:testanaly} aufgetretenen Fehlerursachen zu beheben und dadurch die Ersetzbarkeit im Gesamten noch einmal zu verbessern. \\\\Das in Kapitel \ref{sec:prob} erwähnte Problem der Erschöpfung von Testern sowie Anspruchnahme von Zeit zum Erstellen von \textit{JUnit Tests} kann durch die Verwendung von \textit{Large Language Models} reduziert werden. Speziell bei der Testgenerierung von \textit{JUnit Tests} kann ein Sprachmodell den Tester unterstützen und somit Zeit und Aufwand sparen.

\section{Ausblick}
Die Integration von \textit{Large Language Models} in den Testprozess ist somit eine Bereicherung für die Softwareentwicklung. Es bleibt Raum für Verbesserungen und Weiterentwicklungen, um das Potenzial dieser Technologie auszuschöpfen. Erweiterte Mechanismen zur Fehlererkennung und Fehlerkorrektur innerhalb eines Testerstellungssystems könnten die Qualität der generierten Tests erheblich steigern. Eine detailreichere Aufteilung einzelner Aufgaben auf verschiedene \textit{Prompts} erzielt mit hoher Wahrscheinlichkeit präzisere Testergebnisse. Das aufgestellte Konzept kann in verschiedenen Programmiersprachen Anwendung finden und somit für weitere Analysen im Bereich der automatisierten Testgenerierung genutzt werden. Dies bietet die Möglichkeit wertvolle Erkenntnisse zu gewinnen und dadurch zur kontinuierlichen Verbesserung der Technologie im Kontext der automatisierten Testerstellung beizutragen.  