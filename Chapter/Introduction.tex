%!TeX root = ./../Thesis.tex

%##########################################################
% Inhalt
%##########################################################
\pagenumbering{arabic}
\chapter{Einleitung}

In den letzten Jahren haben \acs{KI}-Technologien in nahezu allen Bereichen des Lebens an Bedeutung gewonnen. Besonders generative KI-Modelle wie ChatGPT 
demonstrieren ihr Potenzial und sind heutzutage aus der Softwareentwicklung nicht mehr wegzudenken. \cite{hammermann_ki_nodate} Durch die Vielzahl an Automatisierungsmöglichkeiten
im Entwicklungsprozess, kann KI zur Effizienzsteigerung und Kosteneinsparung beitragen.\\
Der Softwareentwicklungszyklus (engl. kurz \acs{SDLC}), ein weit verbreiteter Ansatz, unterteilt den Entwicklungsprozess in einzelne Phasen, was den gezielten Einsatz 
von KI zur Unterstützung spezifischer Aufgaben ermöglicht.\\ Insbesondere das Testen von Software, als eine dieser Phasen im SDLC,
spielt eine zentrale Rolle bei der Sicherung von Codequaltiät, dem Vorbeugen von Fehlern und der Überprüfung von Anforderungen. \cite{noauthor_was_nodate} Durch den Einsatz von \textit{Large Language Models} (kurz LLM) erhofft man sich im Testprozess eine 
Entlastung der Entwickler und somit eine Produktivitätssteigerung in der Entwicklung.


\section{Problemstellung}
Das Testen von Software ist ein wichtiger, unverzichtbarer Bestandteil der Softwareentwicklung. Frühes und qualitatives Testen stellt sicher, dass
Fehler bei Ihrer Entstehung erkannt und somit Kosten und Aufwand gespart werden. Dies bringt jedoch Nachteile mit sich, da umfassende Tests ressourcen- und zeitaufwendig sein können. 
Sie können Tester erschöpfen und viel Zeit in Anspruch nehmen, da sie oft manuell durchgeführt und bis zur Erreichung eines fehlerfreien Zustands mehrfach wiederholt werden müssen. \cite{pargaonkar_study_2023}\\
Somit rückt der Einsatz von LLMs immer mehr in den Fokus, um die genannten Nachteile zu kompensieren und die Tester zu unterstützen. KI-Tools wie GitHub-Copilot und ChatGPT 
bieten ein enormes Potenzial bei der Generierung von Code und assistieren dem Tester bei seiner Arbeit. Beide Systeme basieren auf einem LLM von OpenAI 
und fungieren als Chatbots, die auf bestimmte Eingabeaufforderungen (\textit{Prompts}) antworten. Analysen zeigen, dass diese Systeme nicht vollständig zuverlässig sind, da sie bei komplexeren Anforderungen Unsicherheiten aufweisen. \cite{poldrack_ai-assisted_2023}
Aus diesem Grund ist eine manuelle Nachbearbeitung essenziell.
Wie sich LLMs verhalten, wenn sie die Rolle eines Testers übernehmen, ist abhängig von einer Vielzahl von Parameterkombinationen und bietet somit einen 
umfangreichen Forschungsraum. Es stellt sich die Frage, ob der gewünschte Vorteil der Arbeitsentlastung oder gar Ersetzung tatsächlich eintritt.
\\\\Um ein LLM der Rolle des Testers so nah wie möglich zu bringen, bedarf es der Einbindung in ein System, welches ein automatisiertes Generieren von Tests, ohne manuellen
Einfluss, ermöglicht. Einer Umfrage zur Folge, ist das Testen von Units \textit{(Unit Testing)} eine der grundlegendsten Methoden, die ebenfalls die größte Aufmerksamkeit von Entwicklern erhält. \cite{garousi_survey_2013}
Im Kontext Java-basierter Anwendungen ist die Entwicklung eines zuverlässigen Systems, zur automatisierten Generierung dieser Tests, auf Basis eines LLMs von entscheidender Bedeutung.\\
Somit eröffnet sich die Möglichkeit, Sprachmodelle hinsichtlich ihrer Eignung zur automatisierten Generierung von Unit Tests im Vergleich zu manuellen Testern zu evaluieren.
Des Weiteren ist zu berücksichtigen, dass das Design des Prompts einen maßgeblichen Einfluss auf die erzielten Ergebnisse ausübt. Daher ist ein Experimentieren mit verschiedenen Promptdesigns erforderlich, um die Vollständigkeit eines solchen Systems zu gewährleisten.


\section{Zielstellung} 
Zu Beginn der Arbeit werden relevante technische Grundlagen geschaffen, welche im Verlauf der Arbeit essenziell sind, um die zur Lösung der Problemstellung beitragenden Technologien und Konzepte zu verstehen.\\\\
Um die Sprachmodelle effizient nutzen zu können, müssen zunächst verschiedene Prompts designed und anschließend analysiert werden. Dabei soll der Fokus auf grundlegenden Prompt-Techniken wie dem \textit{Zero-Shot-} und \textit{Few-Shot-Prompting} liegen.
Ein weiterer Bestandteil des \textit{Prompt Engineering} sind LLM-Parameter, welche die Ergebnisse des \textit{Outputs} (engl. für Ausgabe) beeinflussen. Damit ist es essenziell eine Kombination aus verschieden gesetzten Parametern und Promptdesigns
zu analysieren.\\\\Die Basis des Ganzen bildet ein Testerstellungssystem, das ein Sprachmodell integriert, um Unit Tests zu erzeugen. Hierbei soll die Programmiersprache Python genutzt werden, um ein zuverlässiges Programmgerüst um das Sprachmodell zu bauen. 
Um sich der Rolle des Testers anzunähern, werden Funktionen wie \textit{Repair Rounds} (engl. für Reparatur Runden) implementiert. Dadurch hat das Modell die Möglichkeit, sich wie ein echter Softwaretester zu verbessern. Wichtig ist, nicht in die Ergebnisse des Modells einzugreifen, sodass eine klare Bewertung der Qualität möglich ist.\\\\
Zu einer hochwertigen Qualtitätsanalyse gehört ein festes Bewertungsverfahren sowie eine aussagekräftige Anzahl an generierten Tests. Neben einer Auswahl von Projekten mit unterschiedlichen Komplexitätsgraden, ist es erforderlich, im Vorfeld klare und aussagekräftige Metriken zu definieren, die bei allen Projekten verwendet werden.    
